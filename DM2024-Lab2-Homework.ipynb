{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: Sofiia Stankevich 妮雅\n",
    "\n",
    "Student ID: S10910630\n",
    "\n",
    "GitHub ID: stankevichhhh\n",
    "\n",
    "Kaggle name: stankevichhhh\n",
    "\n",
    "Kaggle private scoreboard snapshot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home exercises** in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developing the model for the competition (You can use code and comment on it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Home exercises\n",
    "\n",
    "https://github.com/stankevichhhh/DM2024-Lab2-Master/blob/main/DM2024-Lab2-Master.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Participation in the in-class Kaggle Competition\n",
    "* 26th November screenshot:\n",
    " <img src=\"position_nov_26.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Report of work developing the model for the competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required python libraries and modules\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# providing required data\n",
    "data = []\n",
    "with open('/kaggle/input/dm-2024-isa-5810-lab-2-homework/tweets_DM.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# providing data for further training\n",
    "emotion = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv')\n",
    "data_identification = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv')\n",
    "\n",
    "# creating merged DataFrame with all needed information\n",
    "df = pd.DataFrame(data)\n",
    "_source = df['_source'].apply(lambda x: x['tweet'])\n",
    "df = pd.DataFrame({\n",
    "    'tweet_id': _source.apply(lambda x: x['tweet_id']),\n",
    "    'hashtags': _source.apply(lambda x: x['hashtags']),\n",
    "    'text': _source.apply(lambda x: x['text']),\n",
    "})\n",
    "df = df.merge(data_identification, on='tweet_id', how='left')\n",
    "\n",
    "# Splitting data into train and test data\n",
    "train_data = df[df['identification'] == 'train']\n",
    "test_data = df[df['identification'] == 'test']\n",
    "train_data = train_data.merge(emotion, on='tweet_id', how='left')\n",
    "train_data.drop_duplicates(subset=['text'], keep=False, inplace=True) #removing dublicates\n",
    "\n",
    "# Preparing training data\n",
    "train_data_sample = train_data.sample(frac=0.3, random_state=42) #split is 30/70\n",
    "y_train_data = train_data_sample['emotion']\n",
    "X_train_data = train_data_sample['text']\n",
    "\n",
    "# I use LabelEncoder to encode emotion string in numeric category\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train_data)\n",
    "\n",
    "# splitting further, validation data is 20%\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_data, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "# Tokenizer which will use 10000 of the most common words in initialized dict\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "# Creating tokenized sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, padding='post')\n",
    "X_val_pad = pad_sequences(X_val_seq, padding='post')\n",
    "\n",
    "# Initializing embedding matrix\n",
    "embedding_dim = 100 # size of vectorized representation of each word\n",
    "word_index = tokenizer.word_index # tokenized dict\n",
    "vocab_size = min(len(word_index) + 1, 10000) # initialize the max number of unique words\n",
    "embedding_matrix = np.random.uniform(-1, 1, (vocab_size, embedding_dim))\n",
    "\n",
    "# Initializing sequential model with 7 layers\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], trainable=True),\n",
    "    Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(le.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "#1. Embedding: This layer converts integers (indexed words) into dense vectors of fixed length (output_dim). The weights of the layer are initialized by a random matrix (weights=[embedding_matrix]), and they are trainable (trainable=True). \n",
    "#2. Conv1D: A convolution layer with 128 filters and a convolution window of size 5. The activating function is ReLU.\n",
    "#3. GlobalMaxPooling1D: Global pooling layer that selects the maximum value along the time axis (in this case text).\n",
    "#4. Dropout: A regularization layer that shuts down randomly 50% of neurons during the training phase to prevent overtraining.\n",
    "#5. Dense: A fully connected layer with 64 neurons and ReLU activation.\n",
    "#6. Dropout: Another regularization layer with 50% of neurons disabled.\n",
    "#7. Dense: Output fully connected layer with number of classes equal to the number of labels (len(le.classes_)) and softmax activation for multi-class classification.\n",
    "\n",
    "# The model is compiled using Adam optimizer, sparse_categorical_crossentropy loss function suitable for multiclass classification tasks, and accuracy metric.\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model learning\n",
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit(\n",
    "        X_train_pad, y_train,\n",
    "        validation_data=(X_val_pad, y_val),\n",
    "        batch_size=128,\n",
    "        epochs=10,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "test_texts = test_data['text']\n",
    "test_seq = tokenizer.texts_to_sequences(test_texts)\n",
    "X_test_pad = pad_sequences(test_seq, padding='post')\n",
    "y_test_pred = model.predict(X_test_pad)\n",
    "\n",
    "# Changing predictions into labels\n",
    "y_test_pred_labels = le.inverse_transform(np.argmax(y_test_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving predictions to further submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['tweet_id'],\n",
    "    'emotion': y_test_pred_labels\n",
    "})\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
